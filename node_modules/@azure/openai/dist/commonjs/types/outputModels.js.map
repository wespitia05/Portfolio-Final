{"version":3,"file":"outputModels.js","sourceRoot":"","sources":["../../../src/types/outputModels.ts"],"names":[],"mappings":";AAAA,uCAAuC;AACvC,kCAAkC","sourcesContent":["// Copyright (c) Microsoft Corporation.\n// Licensed under the MIT License.\n\nimport type { ErrorModel } from \"@azure-rest/core-client\";\n\n/** Information about content filtering evaluated against generated model output. */\nexport interface ContentFilterResultsForChoiceOutput {\n  /**\n   * Describes language related to anatomical organs and genitals, romantic relationships,\n   *  acts portrayed in erotic or affectionate terms, physical sexual acts, including\n   *  those portrayed as an assault or a forced sexual violent act against one’s will,\n   *  prostitution, pornography, and abuse.\n   */\n  sexual?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to hurt, injure, damage, or\n   * kill someone or something; describes weapons, etc.\n   */\n  violence?: ContentFilterResultOutput;\n  /**\n   * Describes language attacks or uses that include pejorative or discriminatory language\n   * with reference to a person or identity group on the basis of certain differentiating\n   * attributes of these groups including but not limited to race, ethnicity, nationality,\n   * gender identity and expression, sexual orientation, religion, immigration status, ability\n   * status, personal appearance, and body size.\n   */\n  hate?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to purposely hurt, injure,\n   * or damage one’s body, or kill oneself.\n   */\n  self_harm?: ContentFilterResultOutput;\n  /** Describes whether profanity was detected. */\n  profanity?: ContentFilterDetectionResultOutput;\n  /**\n   * Describes an error returned if the content filtering system is\n   * down or otherwise unable to complete the operation in time.\n   */\n  error?: ErrorModel;\n  /** Information about detection of protected text material. */\n  protected_material_text?: ContentFilterDetectionResultOutput;\n  /** Information about detection of protected code material. */\n  protected_material_code?: ContentFilterCitedDetectionResultOutput;\n}\n\n/** Represents the outcome of a detection operation against protected resources as performed by content filtering. */\nexport interface ContentFilterCitedDetectionResultOutput {\n  /** A value indicating whether or not the content has been filtered. */\n  filtered: boolean;\n  /** A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. */\n  detected: boolean;\n  /** The internet location associated with the detection. */\n  URL?: string;\n  /** The license description associated with the detection. */\n  license?: string;\n}\n\n/** Content filtering results for a single prompt in the request. */\nexport interface ContentFilterResultsForPromptOutput {\n  /** The index of this prompt in the set of prompt results */\n  prompt_index: number;\n  /** Content filtering results for this prompt */\n  content_filter_results: ContentFilterResultDetailsForPromptOutput;\n}\n\n/** Information about content filtering evaluated against input data to Azure OpenAI. */\nexport interface ContentFilterResultDetailsForPromptOutput {\n  /**\n   * Describes language related to anatomical organs and genitals, romantic relationships,\n   *  acts portrayed in erotic or affectionate terms, physical sexual acts, including\n   *  those portrayed as an assault or a forced sexual violent act against one’s will,\n   *  prostitution, pornography, and abuse.\n   */\n  sexual?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to hurt, injure, damage, or\n   * kill someone or something; describes weapons, etc.\n   */\n  violence?: ContentFilterResultOutput;\n  /**\n   * Describes language attacks or uses that include pejorative or discriminatory language\n   * with reference to a person or identity group on the basis of certain differentiating\n   * attributes of these groups including but not limited to race, ethnicity, nationality,\n   * gender identity and expression, sexual orientation, religion, immigration status, ability\n   * status, personal appearance, and body size.\n   */\n  hate?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to purposely hurt, injure,\n   * or damage one’s body, or kill oneself.\n   */\n  self_harm?: ContentFilterResultOutput;\n  /** Describes whether profanity was detected. */\n  profanity?: ContentFilterDetectionResultOutput;\n  /**\n   * Describes an error returned if the content filtering system is\n   * down or otherwise unable to complete the operation in time.\n   */\n  error?: ErrorModel;\n  /** Whether a jailbreak attempt was detected in the prompt. */\n  jailbreak?: ContentFilterDetectionResultOutput;\n}\n\n/** Information about filtered content severity level and if it has been filtered or not. */\nexport interface ContentFilterResultOutput {\n  /**\n   * Ratings for the intensity and risk level of filtered content.\n   *\n   * Possible values: \"safe\", \"low\", \"medium\", \"high\"\n   */\n  severity: string;\n  /** A value indicating whether or not the content has been filtered. */\n  filtered: boolean;\n}\n\n/** Represents the outcome of a detection operation performed by content filtering. */\nexport interface ContentFilterDetectionResultOutput {\n  /** A value indicating whether or not the content has been filtered. */\n  filtered: boolean;\n  /** A value indicating whether detection occurred, irrespective of severity or whether the content was filtered. */\n  detected: boolean;\n}\n\n/**\n * A representation of the additional context information available when Azure OpenAI chat extensions are involved\n * in the generation of a corresponding chat completions response. This context information is only populated when\n * using an Azure OpenAI request configured to use a matching extension.\n */\nexport interface AzureChatExtensionsMessageContextOutput {\n  /**\n   * The contextual information associated with the Azure chat extensions used for a chat completions request.\n   * These messages describe the data source retrievals, plugin invocations, and other intermediate steps taken in the\n   * course of generating a chat completions response that was augmented by capabilities from Azure OpenAI chat\n   * extensions.\n   */\n  citations?: Array<AzureChatExtensionDataSourceResponseCitationOutput>;\n  /** The detected intent from the chat history, used to pass to the next turn to carry over the context. */\n  intent?: string;\n}\n\n/**\n * A single instance of additional context information available when Azure OpenAI chat extensions are involved\n * in the generation of a corresponding chat completions response. This context information is only populated when\n * using an Azure OpenAI request configured to use a matching extension.\n */\nexport interface AzureChatExtensionDataSourceResponseCitationOutput {\n  /** The content of the citation. */\n  content: string;\n  /** The title of the citation. */\n  title?: string;\n  /** The URL of the citation. */\n  url?: string;\n  /** The file path of the citation. */\n  filepath?: string;\n  /** The chunk ID of the citation. */\n  chunk_id?: string;\n}\n\n/** Describes the content filtering result for the image generation request. */\nexport interface ImageGenerationContentFilterResults {\n  /**\n   * Describes language related to anatomical organs and genitals, romantic relationships,\n   * acts portrayed in erotic or affectionate terms, physical sexual acts, including\n   * those portrayed as an assault or a forced sexual violent act against one’s will,\n   * prostitution, pornography, and abuse.\n   */\n  sexual?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to hurt, injure, damage, or\n   * kill someone or something; describes weapons, etc.\n   */\n  violence?: ContentFilterResultOutput;\n  /**\n   * Describes language attacks or uses that include pejorative or discriminatory language\n   * with reference to a person or identity group on the basis of certain differentiating\n   * attributes of these groups including but not limited to race, ethnicity, nationality,\n   * gender identity and expression, sexual orientation, religion, immigration status, ability\n   * status, personal appearance, and body size.\n   */\n  hate?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to purposely hurt, injure,\n   * or damage one’s body, or kill oneself.\n   */\n  self_harm?: ContentFilterResultOutput;\n}\n\n/**\n * Describes the content filtering results for the prompt of a image generation request.\n */\nexport interface ImageGenerationPromptFilterResults {\n  /**\n   * Describes language related to anatomical organs and genitals, romantic relationships,\n   * acts portrayed in erotic or affectionate terms, physical sexual acts, including\n   * those portrayed as an assault or a forced sexual violent act against one’s will,\n   * prostitution, pornography, and abuse.\n   */\n  sexual?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to hurt, injure, damage, or\n   * kill someone or something; describes weapons, etc.\n   */\n  violence?: ContentFilterResultOutput;\n  /**\n   * Describes language attacks or uses that include pejorative or discriminatory language\n   * with reference to a person or identity group on the basis of certain differentiating\n   * attributes of these groups including but not limited to race, ethnicity, nationality,\n   * gender identity and expression, sexual orientation, religion, immigration status, ability\n   * status, personal appearance, and body size.\n   */\n  hate?: ContentFilterResultOutput;\n  /**\n   * Describes language related to physical actions intended to purposely hurt, injure,\n   * or damage one’s body, or kill oneself.\n   */\n  self_harm?: ContentFilterResultOutput;\n  /** Describes whether profanity was detected. */\n  profanity?: ContentFilterDetectionResultOutput;\n  /** Whether a jailbreak attempt was detected in the prompt. */\n  jailbreak?: ContentFilterDetectionResultOutput;\n}\n"]}